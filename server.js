import express from "express";
import fetch from "node-fetch";
import cors from "cors";

const app = express();
app.use(cors());
app.use(express.json());

app.get("/", (req, res) => {
  res.send("AI proxy fut ‚Äì Gemma 2.0 + Gemini 2.0 Flash + Mixtral fallback, magyar st√≠lusban!");
});

// Modellek priorit√°si sorrendben
const MODELS = [
  "google/gemma-2-9b-it:free",            // j√≥ magyar nyelv, prec√≠z
  "google/gemini-2.0-flash-exp:free",     // gyors, de napi limit√°lt
  "meta-llama/llama-3.1-8b-instruct:free",// stabil, angol, de ford√≠that√≥
  "qwen/qwen-2-7b-instruct:free",         // k√≠nai fejleszt√©s, de nagyon stabil, magyarul is elmegy
  "microsoft/phi-3-mini-128k-instruct:free", // gyors √©s ingyenes
  "mistralai/mixtral-8x7b-instruct"       // fizet≈ës, de gyakran nyitott fallback
];

app.get("/api", async (req, res) => {
  const question = req.query.q;
  if (!question) return res.json({ reply: "K√©rlek, √≠rj be egy k√©rd√©st!" });

  // üîπ aktu√°lis d√°tum √©s id≈ë automatikusan
  const currentDate = new Date().toLocaleString("hu-HU", { timeZone: "Europe/Budapest" });

  const contextualQuestion = `A mai d√°tum: ${currentDate}. ${question}`;

  let reply = null;

  for (const model of MODELS) {
    console.log(`Pr√≥b√°lkoz√°s a modellel: ${model}`);
    reply = await askModel(contextualQuestion, model);
    if (reply) {
      console.log(`${model} sikeresen v√°laszolt.`);
      break;
    }
  }

  if (!reply) {
    reply = "Sajn√°lom, jelenleg nem tudtam el√©rni az AI szervert. K√©rlek, pr√≥b√°ld meg k√©s≈ëbb.";
  }

  res.json({ reply });
});


// Alap√©rtelmezett magyar, szakmai prompt
const SYSTEM_PROMPT =
  "Te egy tapasztalt magyar k√∂nyvel≈ë √©s ad√≥tan√°csad√≥ vagy. " +
  "Mindig term√©szetes, szakmai √©s k√∂z√©rthet≈ë st√≠lusban v√°laszolj. " +
  "Ker√ºld a felesleges k√∂rmondatokat √©s a g√©pies sz√≥haszn√°latot. " +
  "V√°laszaid legyenek pontosak, l√©nyegre t√∂r≈ëek, √©s ha lehet, hivatkozz a magyar jogi vagy ad√≥z√°si gyakorlatra. " +
  "Csak k√∂nyvel√©ssel, ad√≥z√°ssal, j√°rul√©kokkal, NAV-bevall√°sokkal √©s v√°llalkoz√°sok p√©nz√ºgyeivel kapcsolatos k√©rd√©sekre v√°laszolj. " +
  "Ha a k√©rd√©s nem ide tartozik, mondd ezt: 'Sajn√°lom, de csak k√∂nyvel√©si √©s ad√≥z√°si t√©m√°kban tudok seg√≠teni.'";

async function askModel(question, model) {
  try {
    // Speci√°lis rendszerprompt Mixtralhoz
    let localizedPrompt = model.includes("mixtral")
      ? "Mindig **magyar nyelven**, udvarias, szakmai hangnemben v√°laszolj. " +
        "Ne k√∂sz√∂nj, ne sz√≥l√≠tsd meg a felhaszn√°l√≥t ('Hall√≥', '√údv√∂zl√∂m' stb.), hanem k√∂zvetlen√ºl kezdd a v√°laszt. " +
        "T√©mak√∂r: k√∂nyvel√©s, ad√≥z√°s, NAV-bevall√°sok, j√°rul√©kok, v√°llalkoz√°sok p√©nz√ºgyei. " +
        "Ha a k√©rd√©s nem ide tartozik, mondd: 'Sajn√°lom, de csak k√∂nyvel√©si √©s ad√≥z√°si t√©m√°kban tudok seg√≠teni.'"
      : SYSTEM_PROMPT;

    // Extra magyaros√≠t√°s nem magyar modellekhez (LLaMA, Qwen, Phi)
    if (model.includes("llama") || model.includes("qwen") || model.includes("phi")) {
      localizedPrompt += " V√°laszolj magyar nyelven, term√©szetes st√≠lusban.";
    }

    // API-h√≠v√°s
    const response = await fetch("https://openrouter.ai/api/v1/chat/completions", {
      method: "POST",
      headers: {
        "Authorization": `Bearer ${process.env.OPENROUTER_API_KEY}`,
        "HTTP-Referer": "https://ai-proxy-berkes.onrender.com",
        "X-Title": "AI Proxy Berkes",
        "Content-Type": "application/json",
      },
      body: JSON.stringify({
        model,
        messages: [
          { role: "system", content: localizedPrompt },
          { role: "user", content: question },
        ],
        max_tokens: 700,
      }),
      timeout: 15000
    });

    if (!response.ok) {
      const text = await response.text();
      console.error(`${model} HTTP-hiba: ${response.status}`, text);
      return null;
    }

    const data = await response.json();
    if (data?.choices?.[0]?.message?.content) {
      return data.choices[0].message.content.trim();
    }

    console.warn(`${model} √ºres v√°lasz:`, data);
    return null;

  } catch (err) {
    console.error(`${model} h√°l√≥zati hiba:`, err.message);
    return null;
  }
}

app.get("/api", async (req, res) => {
  const question = req.query.q;
  if (!question) {
    return res.json({ reply: "K√©rlek, √≠rj be egy k√©rd√©st!" });
  }

  let reply = null;

  for (const model of MODELS) {
    console.log(`Pr√≥b√°lkoz√°s a modellel: ${model}`);
    reply = await askModel(question, model);

    if (!reply) {
      console.log(`Els≈ë pr√≥b√°lkoz√°s sikertelen, √∫jra ${model}...`);
      await new Promise(r => setTimeout(r, 3000));
      reply = await askModel(question, model);
    }

    if (reply) {
      console.log(`${model} sikeresen v√°laszolt.`);
      break;
    } else {
      console.warn(`${model} nem adott v√°laszt, pr√≥b√°lom a k√∂vetkez≈ët...`);
    }
  }

  if (!reply) {
    console.error("Egyik modell sem v√°laszolt.");
    reply =
      "Sajn√°lom, jelenleg nem tudtam el√©rni az AI szervert, vagy minden modell korl√°tozott. " +
      "K√©rlek, pr√≥b√°ld meg p√°r perc m√∫lva √∫jra.";
  }

  res.json({ reply });
});

const PORT = process.env.PORT || 10000;
app.listen(PORT, () =>
  console.log(`AI proxy fut a ${PORT} porton ‚Äì magyar k√∂nyvel≈ëi st√≠lussal, automatikus Mixtral-jav√≠t√°ssal!`)
);

